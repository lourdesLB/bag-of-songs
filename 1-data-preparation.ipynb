{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga y preparación del corpus de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este primer notebook es realizar la carga y preprocesamiento del dataset seleccionado de géneros musicales, para su posterior estudio y entrenamiento mediante modelos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloreina/proyecto-aine/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import wave\n",
    "\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceso al conjunto de datos de HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que usaremos para este trabajo se ha obtenido de la librería HuggingFace y recibe el nombre de music genre. En él, nos econtramos con unas 1700 muestras de piezas musicales, en formato mp3 y sampleadas a 22050 Hz. La duración de cada una de ellas varía entre los 270 y 300 segundos. El dataset se encuentra dividio en 3 conjuntos: entrenamiento con 1370 entradas, validación con 171 y test con 172. En cuanto a las categorías, nos encontramos 3 tipos de clasificaciones distitnas para cada dato, desde una más general a otra más concreta. La primera clasificación distingue únicamente las piezas entre música clásica y no clásica. La siguiente hace una distinción entre 9 tipos de géneros musicales distintos y la última y más concreta diferencia entre 16 estilo musicales. Siendo más precisos, la división que se establece en clases es la siguiente:\n",
    "\n",
    "- 1_Classic\n",
    "    - 3_Symphony\n",
    "    - 4_Opera\n",
    "    - 5_Solo\n",
    "    - 6_Chamber\n",
    "\n",
    "- 2_Non_classic\n",
    "    - 7_Pop\n",
    "        - 12_Pop_vocal_ballad\n",
    "        - 13_Adult_contemporary\n",
    "        - 14_Teen_pop\n",
    "\n",
    "    - 8_Dance_and_house\n",
    "        - 15_Contemporary_dance_pop\n",
    "        - 16_Dance_pop\n",
    "\n",
    "    - 9_Indie\n",
    "        - 17_Classic_indie_pop\n",
    "        - 18_Chamber_cabaret_and_art_pop\n",
    "\n",
    "    - 10_Soul_or_r_and_b\n",
    "\n",
    "    - 11_Rock\n",
    "        - 19_Adult_alternative_rock\n",
    "        - 20_Uplifting_anthemic_rock\n",
    "        - 21_Soft_rock\n",
    "        - 22_Acoustic_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmusic_corpus = datasets.load_dataset(\"ccmusic-database/music_genre\", name=\"default\",trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ccmusic_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': 'C:\\\\Users\\\\Usuario\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\9978c1aa27e41c465d1a0a120f523eae02b367b680fff33f401cee81e10d28c4\\\\audio\\\\2_non-classic\\\\11_rock\\\\21_Soft Rock\\\\6573efb8158239c2015abeaea6bb8f65.mp3', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sampling_rate': 22050}, 'mel': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=496x369 at 0x19C52808110>, 'fst_level_label': 1, 'sec_level_label': 8, 'thr_level_label': 14}\n"
     ]
    }
   ],
   "source": [
    "print(ccmusic_corpus['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de la estructura de directorios del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para procesar nuestro dataset una vez ya cargado deberemos de realizar 3 pasos distintos:\n",
    "\n",
    "1. **Anotaciones:** Generaremos un csv que nos servirá para identificar la clase de cada una de las entradas, lo que facilitará su posterior estudio y entrenamiento.\n",
    "\n",
    "2. **Características:** Crearemos otro csv con características extraídas de cada una de las muestras de audio, necesarias para el entrenamiento de modelos de etapas posteriores. Diferenciamos características extraídas del dominio temporal y del frecuencial, que pasamos a detallar a continuación:\n",
    "\n",
    "- Dominio temporal:\n",
    "    - **Amplitude Envelope:** Esta característica mide la envolvente de amplitud de la señal de audio, que es una curva suave que representa la variación máxima de la amplitud del audio en el tiempo. Puede ayudar a identificar la forma de la señal, capturando cómo el nivel de sonido cambia a lo largo de una grabación.\n",
    "\n",
    "    - **Root Mean Square (RMS):** El RMS es una medida de la potencia promedio de la señal de audio. Es efectiva para estimar la \"fuerza\" o energía de la señal en diferentes puntos en el tiempo, lo cual puede ser útil para tareas como la detección de silencios o la estimación de la dinámica de la señal.\n",
    "\n",
    "    - **Zero Crossing Rate (ZCR):** La tasa de cruces por cero mide cuántas veces la señal de audio cruza el eje horizontal, es decir, cuántas veces la amplitud pasa de positiva a negativa y viceversa. Esta característica es útil para identificar la naturaleza percusiva de los sonidos y es comúnmente utilizada en la clasificación de géneros musicales y la detección de ritmo.\n",
    "\n",
    "- Dominio frecuencial:\n",
    "    - **Band Energy Ratio (BER):** Esta característica calcula la relación entre la energía en dos bandas de frecuencia divididas en un umbral específico. Sirve para medir cómo se distribuye la energía entre los bajos y los altos en una señal de audio, proporcionando una idea clara sobre la presencia de tonos graves frente a agudos.\n",
    "\n",
    "    - **Spectral Centroid:** El centroide espectral indica el \"centro de gravedad\" del espectro de frecuencias de una señal. Altos valores sugieren sonidos con presencia de altas frecuencias, mientras que bajos valores indican sonidos más graves. Es útil para caracterizar texturas sonoras.\n",
    "\n",
    "    - **Spectral Bandwidth:** La banda espectral mide la dispersión del espectro alrededor del centroide espectral. Una banda ancha sugiere un sonido más complejo o con ruido, mientras que una banda estrecha indica un sonido más tonal o puro.\n",
    "\n",
    "    - **Chroma STFT:** Esta característica extrae el cromagrama de la señal usando la transformada de Fourier de tiempo corto. Los cromagramas representan la intensidad de las diferentes clases de tonos en la música, útiles para el análisis armónico y la identificación de acordes.\n",
    "\n",
    "    - **Spectral Rolloff:** El rolloff espectral es la frecuencia por debajo de la cual se encuentra un cierto porcentaje de la energía del espectro (comúnmente el 85%). Es una buena medida para determinar el límite superior de las frecuencias presentes en la señal.\n",
    "\n",
    "    - **Mel-Frequency Cepstral Coefficients (MFCC):** Los MFCC son coeficientes que representan el espectro de frecuencias de una señal en la escala Mel, que aproxima mejor la percepción auditiva humana. Son muy populares en el procesamiento del habla y reconocimiento de audio porque capturan las características básicas del timbre y la textura del sonido.\n",
    "\n",
    "\n",
    "3. **Audios:** Almacenaremos los archivos de audios en formato wav, lo que permitirá su carga de manera sencilla en el futuro para visualizaciones y tratamiento de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Funciones auxiliares para la generación de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_envelope(signal,frame_size=1024,hop_length=512):\n",
    "    F=frame_size\n",
    "    H=hop_length\n",
    "    N=signal.shape[0]\n",
    "    # OJO: El último bloque no necesariamente tiene F muestras, pero \n",
    "    # el Python admite rangos a[i:j] fuera del tamaño del array (devuelve lista vacía)  \n",
    "    return np.array([max(signal[k:k+F]) for k in range(0, N, H)])\n",
    "\n",
    "\n",
    "def calculate_ber(signal, split_freq, sample_rate, frame_size=1024, hop_length=512):\n",
    "\n",
    "    # Compute the spectrogram of the signal\n",
    "    spec = librosa.stft(signal, n_fft=frame_size, hop_length=hop_length)\n",
    "\n",
    "    # Calculate the range of frequencies\n",
    "    range_of_freq = sample_rate / 2\n",
    "    # Calculate the change in frequency per bin\n",
    "    change_per_bin = range_of_freq / spec.shape[0]\n",
    "    # Calculate the bin corresponding to the split frequency\n",
    "    split_freq_bin = int(np.floor(split_freq / change_per_bin))\n",
    "\n",
    "    modified_spec = np.abs(spec).T\n",
    "    res = []\n",
    "    for sub_arr in modified_spec:\n",
    "        # Compute the energy in the low-frequency range\n",
    "        low_freq_density = sum(i ** 2 for i in sub_arr[:split_freq_bin])\n",
    "        # Compute the energy in the high-frequency range\n",
    "        high_freq_density = sum(i ** 2 for i in sub_arr[split_freq_bin:])\n",
    "        # Compute the band energy ratio\n",
    "        ber_val = low_freq_density / high_freq_density\n",
    "        res.append(ber_val)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Función para la generación de las características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_features(audio_data, label_column, csv_file):\n",
    "\n",
    "    # Extraer la información del audio (array numpy, sample rate, label)\n",
    "    audio_array = audio_data[\"audio\"][\"array\"]\n",
    "    audio_sr = audio_data[\"audio\"][\"sampling_rate\"]\n",
    "    audio_label = audio_data[label_column]\n",
    "\n",
    "    # Extraer las características del audio \n",
    "\n",
    "    # Dominio temporal\n",
    "    envelope = amplitude_envelope(audio_array)\n",
    "    rms = librosa.feature.rms(y=audio_array)\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio_array)\n",
    "\n",
    "    # Dominio frecuencial\n",
    "    # split_freq a 500 para separar graves de agudos\n",
    "    ber = calculate_ber(audio_array,500, audio_sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=audio_array, sr=audio_sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=audio_array, sr=audio_sr)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio_array, sr=audio_sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio_array, sr=audio_sr)\n",
    "    mfcc = librosa.feature.mfcc(y=audio_array, sr=audio_sr, n_mfcc=13)\n",
    "\n",
    "    # Generar fila para introducir en el CSV\n",
    "    row = f\"{audio_label},{np.mean(envelope)},{np.mean(rms)},{np.mean(zcr)},{np.mean(ber)},{np.mean(spec_cent)},{np.mean(spec_bw)},{np.mean(chroma_stft)},{np.mean(rolloff)}\"\n",
    "    for e in mfcc:\n",
    "        row += f\",{np.mean(e)}\"\n",
    "\n",
    "    # Escribir en el CSV\n",
    "    with open(csv_file, \"a\") as f:\n",
    "        f.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Función para almacenar las anotaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_annotation(file_name, audio_data, label_name, label_dict, csv_file):\n",
    "    label_id = audio_data[label_name]\n",
    "    label = label_dict[label_id]\n",
    "    with open(csv_file, \"a\") as f:\n",
    "        f.write(f\"{file_name},{label_id},{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Función para la generación del fichero wav:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_audio_file(index, audio_data, audio_folder):\n",
    "    audio_folder = audio_folder + str(index) + \".wav\"\n",
    "\n",
    "    audio_array = audio_data[\"audio\"][\"array\"]\n",
    "\n",
    "    ww_obj=wave.open(audio_folder,'w')\n",
    "    ww_obj.setnchannels(1)\n",
    "    ww_obj.setsampwidth(2)\n",
    "    ww_obj.setframerate(22050)\n",
    "\n",
    "    signal=np.int16(audio_array * 32767)\n",
    "    ww_obj.writeframesraw(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Función para la generación del directorio de ficheros del corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus_files(corpus_data, label_column, corpus_folder):\n",
    "\n",
    "    # Crear directorio principal\n",
    "    os.makedirs(corpus_folder, exist_ok=True)\n",
    "\n",
    "    music_genres = {\n",
    "        0: \"Classic\",\n",
    "        2: \"Symphony\",\n",
    "        3: \"Opera\",\n",
    "        4: \"Solo\",\n",
    "        5: \"Chamber\",\n",
    "        1: \"Non_classic\",\n",
    "        6: \"Pop\",\n",
    "        11: \"Pop_vocal_ballad\",\n",
    "        12: \"Adult_contemporary\",\n",
    "        13: \"Teen_pop\",\n",
    "        7: \"Dance_and_house\",\n",
    "        14: \"Contemporary_dance_pop\",\n",
    "        15: \"Dance_pop\",\n",
    "        8: \"Indie\",\n",
    "        16: \"Classic_indie_pop\",\n",
    "        17: \"Chamber_cabaret_and_art_pop\",\n",
    "        9: \"Soul_or_r_and_b\",\n",
    "        10: \"Rock\",\n",
    "        18: \"Adult_alternative_rock\",\n",
    "        19: \"Uplifting_anthemic_rock\",\n",
    "        20: \"Soft_rock\",\n",
    "        21: \"Acoustic_pop\"\n",
    "    }\n",
    "\n",
    "    # Almacenar ficheros de cada partición\n",
    "    for partition in [\"train\", \"validation\", \"test\"]:\n",
    "\n",
    "        # Crear subdirectorios para almacenar los audios\n",
    "        os.makedirs(f\"{corpus_folder}/{partition}/audios\", exist_ok=True)\n",
    "\n",
    "        # Crear fichero de anotaciones\n",
    "        with open(f\"{corpus_folder}/{partition}/annotations.csv\", \"w\") as f:\n",
    "            f.write(\"audio_file,label_id,label_name\\n\")\n",
    "\n",
    "        # Crear fichero de características\n",
    "        with open(f\"{corpus_folder}/{partition}/features.csv\", \"w\") as f:\n",
    "            f.write(\"label,mean_envelope,mean_rms,mean_zcr,\\\n",
    "                    mean_ber,mean_spec_cent,mean_spec_bw,mean_chroma_stft,mean_rolloff,\\\n",
    "                    mean_mfcc1,mean_mfcc2,mean_mfcc3,mean_mfcc4,mean_mfcc5,mean_mfcc6,mean_mfcc7,mean_mfcc8,mean_mfcc9,mean_mfcc10,mean_mfcc11,mean_mfcc12,mean_mfcc13\\n\")\n",
    "            \n",
    "\n",
    "        for i, audio_data in enumerate(corpus_data[partition]):\n",
    "            print(audio_data)\n",
    "            # Guardar características en fichero CSV\n",
    "            store_features(audio_data, label_column, f\"{corpus_folder}/{partition}/features.csv\")\n",
    "\n",
    "            # Guardar anotación en fichero CSV\n",
    "            store_annotation(i, audio_data, label_column, music_genres, f\"{corpus_folder}/{partition}/annotations.csv\")\n",
    "            \n",
    "            # Guardar el audio en formato WAV\n",
    "            store_audio_file(i, audio_data, f\"{corpus_folder}/{partition}/audios/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carga de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_corpus_files(ccmusic_corpus, \"fst_level_label\", \"ccmusic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_corpus_files(ccmusic_corpus, \"sec_level_label\", \"ccmusic2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distinguir géneros musicales utilizando modelos de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Modelos de aprendizaje basados en espectograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Creación del corpus de espectogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para la creación del corpus\n",
    "\n",
    "class SpectrogramDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, annotations_file, audios_dir, transformations=None):\n",
    "        super().__init__\n",
    "        self.annotations = self._leer_csv(annotations_file)\n",
    "        self.audios_dir = audios_dir\n",
    "        self.transformations = transformations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        signal, sr = self._recupera_signal(index)\n",
    "        label = self._recupera_label(index)\n",
    "        if self.transformations:\n",
    "            signal = self.transformations(signal, sr)\n",
    "        return signal, label\n",
    "        \n",
    "    def mapa_label_classes(self):\n",
    "        pares=set([(id_label,label) for [_,id_label,label] in self.annotations])\n",
    "        mapa={}\n",
    "        for (a,b) in pares:\n",
    "            mapa[a]=b\n",
    "        return mapa\n",
    "    \n",
    "    def label_class(self, index):\n",
    "        return self.annotations[index][2]\n",
    "    \n",
    "    def get_audio_file(self, index): \n",
    "        name = self.annotations[index][0]\n",
    "        return os.path.join(name)\n",
    "\n",
    "    def _leer_csv(self,annotations_file):\n",
    "        with open(annotations_file, 'r', encoding='utf-8') as f:\n",
    "            lector = csv.reader(f)\n",
    "            next(lector) \n",
    "            data = [ (file_name, classID, classLabel)  \n",
    "                for file_name, classID, classLabel in lector]\n",
    "        return data\n",
    "\n",
    "    def _recupera_signal(self,index=0):\n",
    "        audio_file=self.get_audio_file(index)        \n",
    "        signal, sr = torchaudio.load(audio_file)\n",
    "        return signal, sr\n",
    "    \n",
    "    def _recupera_label(self, index):\n",
    "        return torch.tensor(int(self.annotations[index][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(signal, sr):\n",
    "    spectrogram_transform = torchaudio.transforms.Spectrogram(power=2)\n",
    "    spec_amplitud_to_db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "    spect = spectrogram_transform(signal)\n",
    "    spect=spec_amplitud_to_db_transform(spect)\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmusic_train = SpectrogramDataset(annotations_file='./ccmusic/train/annotations.csv', \n",
    "                                    audios_dir='./ccmusic/train/audios', \n",
    "                                    transformations=get_spectrogram)\n",
    "ccmusic_train_dataloader = torch.utils.data.DataLoader(ccmusic_train, \n",
    "                                                       batch_size=BATCH_SIZE, \n",
    "                                                       shuffle=True)\n",
    "\n",
    "ccmusic_validation = SpectrogramDataset(annotations_file='./ccmusic/validation/annotations.csv',\n",
    "                                        audios_dir='./ccmusic/validation/audios',\n",
    "                                        transformations=get_spectrogram)\n",
    "ccmusic_validation_dataloader = torch.utils.data.DataLoader(ccmusic_validation, \n",
    "                                                            batch_size=BATCH_SIZE, \n",
    "                                                            shuffle=True)\n",
    "\n",
    "ccmusic_test = SpectrogramDataset(annotations_file='./ccmusic/test/annotations.csv',\n",
    "                                    audios_dir='./ccmusic/test/audios',\n",
    "                                    transformations=get_spectrogram)\n",
    "ccmusic_test_dataloader = torch.utils.data.DataLoader(ccmusic_test, \n",
    "                                                      batch_size=BATCH_SIZE, \n",
    "                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmusic2_train = SpectrogramDataset(annotations_file='./ccmusic2/train/annotations.csv',\n",
    "                                    audios_dir='./ccmusic2/train/audios',\n",
    "                                    transformations=get_spectrogram)\n",
    "ccmusic2_train_dataloader = torch.utils.data.DataLoader(ccmusic2_train,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            shuffle=True)\n",
    "\n",
    "ccmusic2_validation = SpectrogramDataset(annotations_file='./ccmusic2/validation/annotations.csv',\n",
    "                                        audios_dir='./ccmusic2/validation/audios',\n",
    "                                        transformations=get_spectrogram)\n",
    "ccmusic2_validation_dataloader = torch.utils.data.DataLoader(ccmusic2_validation,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            shuffle=True)\n",
    "\n",
    "ccmusic2_test = SpectrogramDataset(annotations_file='./ccmusic2/test/annotations.csv',\n",
    "                                    audios_dir='./ccmusic2/test/audios',\n",
    "                                    transformations=get_spectrogram)\n",
    "ccmusic2_test_dataloader = torch.utils.data.DataLoader(ccmusic2_test,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 201, 3308])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "espectograma, etiqueta = ccmusic_train[0]\n",
    "print(espectograma.shape)\n",
    "print(etiqueta)\n",
    "\n",
    "SPECTOGRAM_H = 201\n",
    "SPECTOGRAM_W = 3308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Definición del modelo CNN para clasificación de espectogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_tam_capa_lineal1(spect_height, spect_width):\n",
    "\n",
    "    def pool_size(size, kernel_size, stride):\n",
    "        return (size - kernel_size) // stride + 1\n",
    "    \n",
    "    def conv_size(size, kernel_size, stride, padding):\n",
    "        return (size + 2*padding - kernel_size) // stride + 1\n",
    "\n",
    "    height_salida = spect_height\n",
    "    width_salida = spect_width\n",
    "\n",
    "    # Bloque convolucional: kernel_size=3, stride=1, padding=1\n",
    "\n",
    "    for _ in range(1, 4):\n",
    "        height_salida = pool_size(conv_size(height_salida, 3, 1, 1), 2, 2)\n",
    "        width_salida = pool_size(conv_size(width_salida, 3, 1, 1), 2, 2)\n",
    "\n",
    "    return height_salida * width_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, spect_height, spect_width, num_labels):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Definir bloque convolucional\n",
    "        self.conv_block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, \n",
    "                            kernel_size=3, \n",
    "                            stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = torch.nn.Sequential( \n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                            kernel_size=3, \n",
    "                            stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                            kernel_size=3, \n",
    "                            stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        height_width_salida = calcula_tam_capa_lineal1(spect_height, spect_width)\n",
    "\n",
    "        self.mlp_block = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(1, -1),\n",
    "            torch.nn.Linear( 128 * height_width_salida, 512), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),  \n",
    "            torch.nn.Linear(512, num_labels if num_labels > 2 else 1),    \n",
    "            torch.nn.Softmax(dim=1) if num_labels > 2 else torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv_block1(input)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        predictions = self.mlp_block(x)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for inputs, targets in dataloader:\n",
    "        print('.', end='')\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_fn(predictions, targets.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return(loss.item())\n",
    "\n",
    "\n",
    "def train(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    print(\"Inicio del entrenamiento\")\n",
    "    for i in range(epochs):\n",
    "        print(f\"Época {i+1} \" ,end='') \n",
    "        print('.', end='')\n",
    "        loss=train_single_epoch(model, dataloader, loss_fn, optimizer)\n",
    "        print(f\"\\nLoss: {loss}\")\n",
    "    print(\"Fin del entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Entrenamiento e inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = CNNModel(spect_height=SPECTOGRAM_H, spect_width=SPECTOGRAM_W, num_labels=2)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), \n",
    "                             lr=LEARNING_RATE)\n",
    "train(modelo, ccmusic_train_dataloader, loss_fn, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = CNNModel(spect_height=SPECTOGRAM_H, spect_width=SPECTOGRAM_W, num_labels=9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), \n",
    "                             lr=LEARNING_RATE)\n",
    "train(modelo, ccmusic2_train_dataloader, loss_fn, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Modelos de aprendizaje basados en extracción de características (*bag of songs*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "train_df = pd.read_csv('ccmusic/train/features.csv')\n",
    "test_df = pd.read_csv('ccmusic/test/features.csv')\n",
    "validation_df = pd.read_csv('ccmusic/validation/features.csv')\n",
    "\n",
    "# Eliminar columnas no necesarias\n",
    "train_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "test_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "validation_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "test_df['label'] = label_encoder.transform(test_df['label'])\n",
    "validation_df['label'] = label_encoder.transform(validation_df['label'])\n",
    "\n",
    "# Separar las características y las etiquetas\n",
    "X_train = train_df.drop('label', axis=1).values\n",
    "y_train = train_df['label'].values\n",
    "X_test = test_df.drop('label', axis=1).values\n",
    "y_test = test_df['label'].values\n",
    "X_val = validation_df.drop('label', axis=1).values\n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=21, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definición del modelo\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = Classifier(num_features, num_classes)\n",
    "print(model)\n",
    "\n",
    "# Configuración de la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.19214338064193726, Validation Loss: 0.24798855185508728\n",
      "Epoch 2, Training Loss: 0.09617410600185394, Validation Loss: 0.1489162395397822\n",
      "Epoch 3, Training Loss: 0.06668626517057419, Validation Loss: 0.125129667421182\n",
      "Epoch 4, Training Loss: 0.06241731345653534, Validation Loss: 0.11546906580527623\n",
      "Epoch 5, Training Loss: 0.06514333933591843, Validation Loss: 0.10933728764454524\n",
      "Epoch 6, Training Loss: 0.061320483684539795, Validation Loss: 0.10551605621973674\n",
      "Epoch 7, Training Loss: 0.07443602383136749, Validation Loss: 0.10577847560246785\n",
      "Epoch 8, Training Loss: 0.05509546771645546, Validation Loss: 0.09459401667118073\n",
      "Epoch 9, Training Loss: 0.048574186861515045, Validation Loss: 0.09193692977229755\n",
      "Epoch 10, Training Loss: 0.052683793008327484, Validation Loss: 0.09190963084499042\n",
      "Epoch 11, Training Loss: 0.040546663105487823, Validation Loss: 0.08386822541554768\n",
      "Epoch 12, Training Loss: 0.0399075448513031, Validation Loss: 0.08391079927484195\n",
      "Epoch 13, Training Loss: 0.029635842889547348, Validation Loss: 0.08011749262611072\n",
      "Epoch 14, Training Loss: 0.03664885088801384, Validation Loss: 0.08130733047922452\n",
      "Epoch 15, Training Loss: 0.02856994979083538, Validation Loss: 0.0786681342869997\n",
      "Epoch 16, Training Loss: 0.03647485747933388, Validation Loss: 0.07935241609811783\n",
      "Epoch 17, Training Loss: 0.04257414489984512, Validation Loss: 0.08065550339718659\n",
      "Epoch 18, Training Loss: 0.03331873193383217, Validation Loss: 0.0791334795455138\n",
      "Epoch 19, Training Loss: 0.0454709455370903, Validation Loss: 0.08415250045557816\n",
      "Epoch 20, Training Loss: 0.04211918264627457, Validation Loss: 0.07862675500412782\n",
      "Epoch 21, Training Loss: 0.05451062694191933, Validation Loss: 0.0888062712425987\n",
      "Epoch 22, Training Loss: 0.05038738623261452, Validation Loss: 0.08320296928286552\n",
      "Epoch 23, Training Loss: 0.037757497280836105, Validation Loss: 0.07882716196278731\n",
      "Epoch 24, Training Loss: 0.036862269043922424, Validation Loss: 0.08096566175421079\n",
      "Epoch 25, Training Loss: 0.02554403990507126, Validation Loss: 0.09418706347544988\n",
      "Stopping early due to no improvement\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de entrenamiento con early stopping\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, patience=5):\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print('Stopping early due to no improvement')\n",
    "            break\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=50)\n",
    "\n",
    "# Cargar el mejor modelo para evaluación\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.26%\n",
      "F1 Score on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(loader):\n",
    "    model.eval()  # Poner el modelo en modo evaluación\n",
    "    predictions, labels_list = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())  # Guarda las predicciones para calcular el F1\n",
    "            labels_list.extend(labels.cpu().numpy())  # Guarda las etiquetas verdaderas\n",
    "\n",
    "    accuracy = accuracy_score(labels_list, predictions) * 100\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')  # Puedes cambiar 'weighted' por 'macro' o 'micro' según tus necesidades\n",
    "\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "    print(f'F1 Score on test set: {f1:.2f}')\n",
    "\n",
    "# Llamamos a la función de evaluación con el conjunto de prueba\n",
    "evaluate_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

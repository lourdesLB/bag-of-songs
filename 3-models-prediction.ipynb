{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "train_df = pd.read_csv('ccmusic/train/features.csv')\n",
    "test_df = pd.read_csv('ccmusic/test/features.csv')\n",
    "validation_df = pd.read_csv('ccmusic/validation/features.csv')\n",
    "\n",
    "# Eliminar columnas no necesarias\n",
    "train_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "test_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "validation_df.drop([\"audio_file\"], axis=1, inplace=True)\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "test_df['label'] = label_encoder.transform(test_df['label'])\n",
    "validation_df['label'] = label_encoder.transform(validation_df['label'])\n",
    "\n",
    "# Separar las características y las etiquetas\n",
    "X_train = train_df.drop('label', axis=1).values\n",
    "y_train = train_df['label'].values\n",
    "X_test = test_df.drop('label', axis=1).values\n",
    "y_test = test_df['label'].values\n",
    "X_val = validation_df.drop('label', axis=1).values\n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=21, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definición del modelo\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = Classifier(num_features, num_classes)\n",
    "print(model)\n",
    "\n",
    "# Configuración de la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.19214338064193726, Validation Loss: 0.24798855185508728\n",
      "Epoch 2, Training Loss: 0.09617410600185394, Validation Loss: 0.1489162395397822\n",
      "Epoch 3, Training Loss: 0.06668626517057419, Validation Loss: 0.125129667421182\n",
      "Epoch 4, Training Loss: 0.06241731345653534, Validation Loss: 0.11546906580527623\n",
      "Epoch 5, Training Loss: 0.06514333933591843, Validation Loss: 0.10933728764454524\n",
      "Epoch 6, Training Loss: 0.061320483684539795, Validation Loss: 0.10551605621973674\n",
      "Epoch 7, Training Loss: 0.07443602383136749, Validation Loss: 0.10577847560246785\n",
      "Epoch 8, Training Loss: 0.05509546771645546, Validation Loss: 0.09459401667118073\n",
      "Epoch 9, Training Loss: 0.048574186861515045, Validation Loss: 0.09193692977229755\n",
      "Epoch 10, Training Loss: 0.052683793008327484, Validation Loss: 0.09190963084499042\n",
      "Epoch 11, Training Loss: 0.040546663105487823, Validation Loss: 0.08386822541554768\n",
      "Epoch 12, Training Loss: 0.0399075448513031, Validation Loss: 0.08391079927484195\n",
      "Epoch 13, Training Loss: 0.029635842889547348, Validation Loss: 0.08011749262611072\n",
      "Epoch 14, Training Loss: 0.03664885088801384, Validation Loss: 0.08130733047922452\n",
      "Epoch 15, Training Loss: 0.02856994979083538, Validation Loss: 0.0786681342869997\n",
      "Epoch 16, Training Loss: 0.03647485747933388, Validation Loss: 0.07935241609811783\n",
      "Epoch 17, Training Loss: 0.04257414489984512, Validation Loss: 0.08065550339718659\n",
      "Epoch 18, Training Loss: 0.03331873193383217, Validation Loss: 0.0791334795455138\n",
      "Epoch 19, Training Loss: 0.0454709455370903, Validation Loss: 0.08415250045557816\n",
      "Epoch 20, Training Loss: 0.04211918264627457, Validation Loss: 0.07862675500412782\n",
      "Epoch 21, Training Loss: 0.05451062694191933, Validation Loss: 0.0888062712425987\n",
      "Epoch 22, Training Loss: 0.05038738623261452, Validation Loss: 0.08320296928286552\n",
      "Epoch 23, Training Loss: 0.037757497280836105, Validation Loss: 0.07882716196278731\n",
      "Epoch 24, Training Loss: 0.036862269043922424, Validation Loss: 0.08096566175421079\n",
      "Epoch 25, Training Loss: 0.02554403990507126, Validation Loss: 0.09418706347544988\n",
      "Stopping early due to no improvement\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de entrenamiento con early stopping\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, patience=5):\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print('Stopping early due to no improvement')\n",
    "            break\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=50)\n",
    "\n",
    "# Cargar el mejor modelo para evaluación\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.26%\n",
      "F1 Score on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(loader):\n",
    "    model.eval()  # Poner el modelo en modo evaluación\n",
    "    predictions, labels_list = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())  # Guarda las predicciones para calcular el F1\n",
    "            labels_list.extend(labels.cpu().numpy())  # Guarda las etiquetas verdaderas\n",
    "\n",
    "    accuracy = accuracy_score(labels_list, predictions) * 100\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')  # Puedes cambiar 'weighted' por 'macro' o 'micro' según tus necesidades\n",
    "\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "    print(f'F1 Score on test set: {f1:.2f}')\n",
    "\n",
    "# Llamamos a la función de evaluación con el conjunto de prueba\n",
    "evaluate_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
